{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho-LjRGgDgkK",
        "outputId": "435259a1-8299-4e63-ca8e-f41254eb2120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Collecting apex\n",
            "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Collecting cryptacular (from apex)\n",
            "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy (from apex)\n",
            "  Downloading zope.sqlalchemy-3.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting velruse>=1.0.3 (from apex)\n",
            "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyramid>1.1.2 (from apex)\n",
            "  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pyramid_mailer (from apex)\n",
            "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting wtforms (from apex)\n",
            "  Downloading wtforms-3.2.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting wtforms-recaptcha (from apex)\n",
            "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting hupper>=1.5 (from pyramid>1.1.2->apex)\n",
            "  Downloading hupper-1.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting plaster (from pyramid>1.1.2->apex)\n",
            "  Downloading plaster-1.1.2-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting plaster-pastedeploy (from pyramid>1.1.2->apex)\n",
            "  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyramid>1.1.2->apex) (75.1.0)\n",
            "Collecting translationstring>=0.4 (from pyramid>1.1.2->apex)\n",
            "  Downloading translationstring-1.4-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting venusian>=1.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading venusian-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting webob>=1.8.3 (from pyramid>1.1.2->apex)\n",
            "  Downloading WebOb-1.8.9-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading zope.deprecation-5.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from velruse>=1.0.3->apex) (2.0.0)\n",
            "Collecting anykeystore (from velruse>=1.0.3->apex)\n",
            "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python3-openid (from velruse>=1.0.3->apex)\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pbkdf2 (from cryptacular->apex)\n",
            "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting repoze.sendmail>=4.1 (from pyramid_mailer->apex)\n",
            "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting transaction (from pyramid_mailer->apex)\n",
            "  Downloading transaction-5.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /usr/local/lib/python3.11/dist-packages (from zope.sqlalchemy->apex) (2.0.39)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (3.1.1)\n",
            "Collecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex)\n",
            "  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.2.2)\n",
            "Downloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading wtforms-3.2.1-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\n",
            "Downloading hupper-1.12.1-py3-none-any.whl (22 kB)\n",
            "Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transaction-5.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
            "Downloading venusian-3.1.1-py3-none-any.whl (14 kB)\n",
            "Downloading WebOb-1.8.9-py2.py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.deprecation-5.1-py3-none-any.whl (10 kB)\n",
            "Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46441 sha256=c91d8c2d4993276c73677c4668d5e39bfe048d4107d7f1a19c885c368018e99e\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/70/2e/c33962b405031e5f065612a949e72908bae5d41e6f121733e1\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50905 sha256=3cc82faa71d930aa3cc606ce67f94f9465d6c777a2f90402907da0d0b94ebf16\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/5a/67/73d880832b2687c5493d22745103572c82394918e95fe566aa\n",
            "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp311-cp311-linux_x86_64.whl size=55936 sha256=f671a6ab8e933e44683920c656cb81d7471c9c3bad86c541ccc1df5fa26229cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/04/b9/2c265ad712ec6d44dab61fd5b68767eced0a2d30b8b266fe72\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=679a30991ea231b6d7f6db8e3bb864852315971149392118e53d9516d887179f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/2f/cd/d39c23b24c2c748551befae0d929411ca6d12ff2473ab6c15b\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5082 sha256=15272221f4632a78818e5052924f8c2404b7f5ee409635539950d3dfb4249d7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/15/2c/6ed49942a07c12003206432edb16ae9ab09cf1d62a58a1db64\n",
            "Successfully built apex velruse cryptacular anykeystore pbkdf2\n",
            "Installing collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, python3-openid, plaster, PasteDeploy, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, zope.sqlalchemy, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\n",
            "Successfully installed PasteDeploy-3.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.12.1 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-5.0 translationstring-1.4 velruse-1.1.1 venusian-3.1.1 webob-1.8.9 wtforms-3.2.1 wtforms-recaptcha-0.3.2 zope.deprecation-5.1 zope.interface-7.2 zope.sqlalchemy-3.1\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch torchvision pillow scikit-learn pandas numpy imbalanced-learn apex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from transformers import AutoImageProcessor, EfficientNetForImageClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n"
      ],
      "metadata": {
        "id": "7eZRsZGjH1cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directories\n",
        "train_dir = '/content/drive/My Drive/AJL Team 15/Equitable AI Dermatology 2025/train/train/'\n",
        "augmented_dir = \"/content/drive/My Drive/AJL Team 15/Equitable AI Dermatology 2025/train/train_augmented/\"\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "# Define image data generator for augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_df = pd.read_csv('/content/drive/My Drive/AJL Team 15/Equitable AI Dermatology 2025/train.csv')\n",
        "train_df['md5hash'] = train_df['md5hash'].astype(str) + '.jpg'\n",
        "train_df['file_path'] = train_df['label'] + '/' + train_df['md5hash']\n",
        "\n",
        "# Filter for high-quality images\n",
        "train_df = train_df[train_df['qc'] == \"1 Diagnostic\"]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform augmentation\n",
        "augmented_data = []\n",
        "num_augmented_images = 5  # Increase number of augmented images\n",
        "\n",
        "# Perform augmentation\n",
        "for index, row in train_data.iterrows():\n",
        "    original_image_path = os.path.join(train_dir, row[\"file_path\"])\n",
        "    img = load_img(original_image_path)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    class_label = row[\"label\"]\n",
        "    base_filename = os.path.basename(row[\"file_path\"]).split(\".\")[0]\n",
        "    class_dir = os.path.join(augmented_dir, class_label)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    # Save original image\n",
        "    new_file_path = os.path.join(class_dir, f\"{base_filename}.jpg\")\n",
        "    img.save(new_file_path)\n",
        "    augmented_data.append({\n",
        "        \"file_path\": new_file_path.replace(augmented_dir, \"\"),\n",
        "        \"label\": row[\"label\"],\n",
        "        \"encoded_label\": row[\"encoded_label\"],\n",
        "        \"md5hash\": row[\"md5hash\"],\n",
        "        \"fitzpatrick_scale\": row[\"fitzpatrick_scale\"],\n",
        "        \"fitzpatrick_centaur\": row[\"fitzpatrick_centaur\"],\n",
        "        \"nine_partition_label\": row[\"nine_partition_label\"],\n",
        "        \"three_partition_label\": row[\"three_partition_label\"],\n",
        "        \"qc\": row[\"qc\"],\n",
        "        \"ddi_scale\": row[\"ddi_scale\"]\n",
        "    })\n",
        "\n",
        "    # Generate augmented images\n",
        "    aug_iter = train_datagen.flow(img_array, batch_size=1)\n",
        "    for i in range(num_augmented_images):\n",
        "        aug_img = next(aug_iter)[0]\n",
        "        aug_img = (aug_img * 255).astype(\"uint8\")\n",
        "        aug_pil_img = array_to_img(aug_img)\n",
        "        aug_file_path = os.path.join(class_dir, f\"{base_filename}_aug{i}.jpg\")\n",
        "        aug_pil_img.save(aug_file_path)\n",
        "        augmented_data.append({\n",
        "            \"file_path\": aug_file_path.replace(augmented_dir, \"\"),\n",
        "            \"label\": row[\"label\"],\n",
        "            \"encoded_label\": row[\"encoded_label\"],\n",
        "            \"md5hash\": row[\"md5hash\"],\n",
        "            \"fitzpatrick_scale\": row[\"fitzpatrick_scale\"],\n",
        "            \"fitzpatrick_centaur\": row[\"fitzpatrick_centaur\"],\n",
        "            \"nine_partition_label\": row[\"nine_partition_label\"],\n",
        "            \"three_partition_label\": row[\"three_partition_label\"],\n",
        "            \"qc\": row[\"qc\"],\n",
        "            \"ddi_scale\": row[\"ddi_scale\"]\n",
        "        })\n",
        "\n",
        "# Save augmented metadata\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "augmented_df.to_csv(os.path.join(augmented_dir, \"train_augmented_metadata.csv\"), index=False)\n",
        "print(f\"✅ Augmentation complete. Total images in dataset: {len(augmented_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bgkvcGoH7zm",
        "outputId": "d003f974-1a9b-4679-d29e-292b6538c7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Augmentation complete. Total images in dataset: 360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # Reduced size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Reduced size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "cLZS7xCNNZcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class\n",
        "class DermatologyDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels=None, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx] if self.labels is not None else -1  # Handle None case\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "7HcZhNqgH8go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Function to generate embeddings with data augmentation\n",
        "def generate_embeddings(image_paths, transform, labels=None):\n",
        "    embeddings = []\n",
        "    dataset = DermatologyDataset(image_paths, labels=labels, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    for batch in dataloader:\n",
        "        images, _ = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "        embeddings.append(outputs.logits.numpy())\n",
        "\n",
        "    return np.vstack(embeddings)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "phCRp_7EIBUC",
        "outputId": "e924e54f-e80d-4342-859e-24d4f22889a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Function to generate embeddings with data augmentation\\ndef generate_embeddings(image_paths, transform, labels=None):\\n    embeddings = []\\n    dataset = DermatologyDataset(image_paths, labels=labels, transform=transform)\\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\\n\\n    for batch in dataloader:\\n        images, _ = batch\\n        with torch.no_grad():\\n            outputs = model(images)\\n        embeddings.append(outputs.logits.numpy())\\n    \\n    return np.vstack(embeddings)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image paths and labels for training and validation sets\n",
        "train_image_paths = [os.path.join(train_dir, row[\"file_path\"]) for _, row in train_data.iterrows()]\n",
        "train_labels = train_data['encoded_label'].values\n",
        "\n",
        "val_image_paths = [os.path.join(train_dir, row[\"file_path\"]) for _, row in val_data.iterrows()]\n",
        "val_labels = val_data['encoded_label'].values\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "train_dataset = DermatologyDataset(train_image_paths, labels=train_labels, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # Reduced batch size\n",
        "\n",
        "val_dataset = DermatologyDataset(val_image_paths, labels=val_labels, transform=val_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "5rPIxkJ5IDoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune EfficientNet-B0 (smaller model)\n",
        "model = EfficientNetForImageClassification.from_pretrained(\n",
        "    \"google/efficientnet-b0\",\n",
        "    num_labels=len(label_encoder.classes_),\n",
        "    ignore_mismatched_sizes=True  # Add this line to ignore size mismatches\n",
        ")\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(5):  # Adjust number of epochs\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images).logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_dataset = DermatologyDataset(val_image_paths, labels=val_labels, transform=val_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "val_preds, val_true = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = model(images).logits\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "        val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Get unique labels from val_true\n",
        "unique_labels = np.unique(val_true)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(val_true, val_preds)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Generate classification report with labels argument\n",
        "print(\"Classification Report:\\n\", classification_report(\n",
        "    val_true, val_preds,\n",
        "    target_names=label_encoder.classes_[unique_labels],  # Use unique labels to get target names\n",
        "    labels=unique_labels  # Specify labels for the report\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeyQP5jNIHkN",
        "outputId": "eb090b14-066e-42ee-8219-f8548e780134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EfficientNetForImageClassification were not initialized from the model checkpoint at google/efficientnet-b0 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([1000, 1280]) in the checkpoint and torch.Size([19, 1280]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.92204213142395\n",
            "Epoch 2, Loss: 2.823044776916504\n",
            "Epoch 3, Loss: 2.735992670059204\n",
            "Epoch 4, Loss: 2.701565742492676\n",
            "Epoch 5, Loss: 2.637279748916626\n",
            "Validation Accuracy: 0.1875\n",
            "Classification Report:\n",
            "                                   precision    recall  f1-score   support\n",
            "\n",
            "               actinic-keratosis       0.00      0.00      0.00         2\n",
            "            basal-cell-carcinoma       0.50      0.75      0.60         4\n",
            "basal-cell-carcinoma-morpheiform       0.00      0.00      0.00         1\n",
            "                          eczema       0.00      0.00      0.00         1\n",
            "                  kaposi-sarcoma       0.00      0.00      0.00         1\n",
            "                          keloid       0.00      0.00      0.00         2\n",
            "                        melanoma       0.00      0.00      0.00         2\n",
            "               mycosis-fungoides       0.00      0.00      0.00         1\n",
            "               prurigo-nodularis       0.00      0.00      0.00         1\n",
            "         squamous-cell-carcinoma       0.00      0.00      0.00         1\n",
            "\n",
            "                       micro avg       0.23      0.19      0.21        16\n",
            "                       macro avg       0.05      0.07      0.06        16\n",
            "                    weighted avg       0.12      0.19      0.15        16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "test_df = pd.read_csv('/content/drive/My Drive/AJL Team 15/Equitable AI Dermatology 2025/test.csv')\n",
        "test_df['md5hash'] = test_df['md5hash'].astype(str) + '.jpg'\n",
        "test_image_paths = [os.path.join('/content/drive/My Drive/AJL Team 15/Equitable AI Dermatology 2025/test/test/', row[\"md5hash\"]) for _, row in test_df.iterrows()]\n",
        "\n",
        "# Create a Dataset and DataLoader for the test set\n",
        "test_dataset = DermatologyDataset(test_image_paths, transform=val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Generate predictions for the test set\n",
        "model.eval()\n",
        "test_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        outputs = model(images).logits\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# Convert predicted labels back to original class names\n",
        "predicted_labels = label_encoder.inverse_transform(test_preds)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'md5hash': test_df['md5hash'].str.replace('.jpg', '', regex=False),\n",
        "    'label': predicted_labels\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv3EkdMQIPtE",
        "outputId": "dbe4294c-6112-4255-a5d4-e5e7a7b1909e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the CSV file to your local device\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NXysfLbUKJVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "920fb775-1200-498b-ccb4-b8e3a24ce8d3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b8baf046-ce5e-4f04-810f-fe66021f08d8\", \"submission.csv\", 63544)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}